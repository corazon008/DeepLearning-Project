{
 "cells": [
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import sklearn.metrics\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
    "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, classification_report\n",
    "import os\n",
    "# Move one step in the directory structure to access src\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join('..')))\n",
    "from src.torch.torch_utils import *\n",
    "from src.torch.torch_wrapper import *"
   ],
   "id": "a341c3c1abb8cd0e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df = pd.read_csv('../data/health_lifestyle_dataset_cleaned.csv')",
   "id": "178c2e86e9af3b79",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "df",
   "id": "2f3956ae1108cc6c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "regression_target = ['cholesterol', 'calories_consumed']\n",
    "classification_target = 'disease_risk'\n",
    "\n",
    "regression_features = df.drop(columns=regression_target).values\n",
    "classification_features = df.drop(columns=classification_target).values\n",
    "regression_labels = df[regression_target].values\n",
    "classification_labels = df[classification_target].values"
   ],
   "id": "a64d6db2d46a2ec2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "X_train_reg, X_test_reg, y_train_reg, y_test_reg = train_test_split(\n",
    "    regression_features, regression_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "X_train_clf, X_test_clf, y_train_clf, y_test_clf = train_test_split(\n",
    "    classification_features, classification_labels, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "skf = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)"
   ],
   "id": "9ae5782ba65a66f0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "8ad3477143cd66fb",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Regression",
   "id": "69a05a4f24416e77"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "param_grid = {\n",
    "    \"layers\": [3, 4],\n",
    "    \"width\": [32, 64],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": [20],\n",
    "    #\"loss_fn\": [nn.MSELoss, nn.HuberLoss],\n",
    "    #\"optimizer\": [torch.optim.SGD, torch.optim.Adam], #\n",
    "    \"activation\": [nn.Tanh],\n",
    "    \"batch_size\": [16, 32],\n",
    "    \"dropout_rates\": [[0.3], [0.5, 0.2]],\n",
    "}"
   ],
   "id": "323b10a4657af7da",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid = GridSearchCV(TorchRegressor(), param_grid, cv=3, scoring=\"r2\", n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train_reg, y_train_reg)\n",
    "\n",
    "print(\"Meilleurs paramètres :\", grid.best_params_)\n",
    "print(\"Score :\", grid.best_score_)"
   ],
   "id": "d1123c22a8d116a0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Meilleurs paramètres : {'activation': <class 'torch.nn.modules.activation.Tanh'>, 'dropout_rates': [0.5, 0.2], 'epochs': 30, 'layers': 3, 'loss_fn': <class 'torch.nn.modules.loss.HuberLoss'>, 'lr': 0.001, 'width': 64} \\\n",
    "Score : -0.00048325874797827684\n",
    "\n",
    "\n",
    "10min pour 216 fits \\\n",
    "Meilleurs paramètres : {'activation': <class 'torch.nn.modules.activation.Tanh'>, 'batch_size': 32, 'dropout_rates': [0.5, 0.2], 'epochs': 20, 'layers': 4, 'loss_fn': <class 'torch.nn.modules.loss.MSELoss'>, 'lr': 0.001, 'width': 32} \\\n",
    "Score : -4.377366297199833e-05\\"
   ],
   "id": "1e51b6e4ad9e1540"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model = grid.best_estimator_\n",
    "hist = best_model.loss_history"
   ],
   "id": "eff554a45835c247",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(X_train_reg)\n",
    "mse = mean_squared_error(y_train_reg, y_pred)\n",
    "mae = mean_absolute_error(y_train_reg, y_pred)\n",
    "r2 = r2_score(y_train_reg, y_pred)\n",
    "print(f\"Train MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")"
   ],
   "id": "707a594a799dc7ba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(X_test_reg)\n",
    "mse = mean_squared_error(y_test_reg, y_pred)\n",
    "mae = mean_absolute_error(y_test_reg, y_pred)\n",
    "r2 = r2_score(y_test_reg, y_pred)\n",
    "print(f\"Test MSE: {mse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")"
   ],
   "id": "b038ece536e25ced",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(hist, label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "3f50b7b4a445b58e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## History\n",
    "\n",
    "On n'avait pas standadisé les données dcp les loss était énormes (de l'ordre de 1e36). Apres ca, elles sont entre 1900 et 2400.\n",
    "\n",
    "```python\n",
    "model_reg = RegressionModel(X_train_reg.shape[1], width=512, dropout=[0]).to(device)\n",
    "```\n",
    "\n",
    "Ensuite j'ai essayé avec des architectures plus petites (width=128, puis width=64) et avec du dropout (0.2, 0.5) mais les performances étaient moins bonnes.\n",
    "\n",
    "Final Evaluation:\n",
    "Loss: 1.0004\n",
    "MAE: 0.8677\n",
    "R2: -0.0003"
   ],
   "id": "f4b70c067886aed1"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Classification",
   "id": "c76be15aa936ba22"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "class_weights = compute_class_weights(y_train_clf)\n",
    "\n",
    "param_grid = {\n",
    "    \"layers\": [ 4, 5],\n",
    "    \"width\": [128, 256],\n",
    "    \"lr\": [1e-3],\n",
    "    \"epochs\": [30],\n",
    "    \"class_weights\": [torch.tensor([1.0, 4.5])],\n",
    "    \"loss_fn\": [nn.CrossEntropyLoss],\n",
    "    \"optimizer\": [torch.optim.SGD],\n",
    "    \"activation\": [nn.ReLU],\n",
    "    \"batch_size\": [16],\n",
    "    \"dropout_rates\": [[0.3], [0.5, 0.2]],\n",
    "}"
   ],
   "id": "1866503ef9438b64",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "grid = GridSearchCV(TorchClassifier(), param_grid, cv=skf, scoring=\"accuracy\", n_jobs=-1, verbose=2)\n",
    "grid.fit(X_train_clf, y_train_clf)\n",
    "\n",
    "print(\"Meilleurs paramètres :\", grid.best_params_)\n",
    "print(\"Score :\", grid.best_score_)"
   ],
   "id": "6787ec6eebeb05c7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "Fitting 3 folds for each of 64 candidates, totalling 192 fits \\\n",
    "Meilleurs paramètres : {'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batch_size': 16, 'dropout_rates': [0.0], 'epochs': 30, 'layers': 3, 'loss_fn': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'lr': 0.01, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'width': 64}\\\n",
    "Score : 0.7517124999224092\n",
    "\n",
    "6min pour 108 fits \\\n",
    "Meilleurs paramètres : {'activation': <class 'torch.nn.modules.activation.ReLU'>, 'batch_size': 16, 'class_weights': tensor([0.6651, 2.0138]), 'dropout_rates': [0.3], 'epochs': 30, 'layers': 3, 'loss_fn': <class 'torch.nn.modules.loss.CrossEntropyLoss'>, 'lr': 0.01, 'optimizer': <class 'torch.optim.sgd.SGD'>, 'width': 32} \\\n",
    "Score : 0.7517124999224092"
   ],
   "id": "411895d168df7962"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "Xsmall = X_test_clf[:8]\n",
    "import torch\n",
    "logits = best_model.model(torch.tensor(Xsmall, dtype=torch.float32))\n",
    "print(\"logits shape:\", logits.shape)  # devrait être (8,2) ou (8,1)\n",
    "print(logits[:5])"
   ],
   "id": "a4dbd2e8d28f7b4e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "best_model :Skwrapper = grid.best_estimator_\n",
    "hist = best_model.loss_history"
   ],
   "id": "e2d42c317a2f8ce7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "probs = best_model.predict_proba(X_test_clf)\n",
    "print(\"max prob class 1:\", probs[:, 1].max())\n",
    "print(\"mean prob class 1:\", probs[:, 1].mean())\n"
   ],
   "id": "77a5c218f4432d57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(X_train_clf)\n",
    "f1 = f1_score(y_train_clf, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_train_clf, y_pred)\n",
    "print(f\"Train F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "id": "20ce6453f12f9ade",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = best_model.predict(X_test_clf, 0.5830)\n",
    "f1 = sklearn.metrics.f1_score(y_test_clf, y_pred, average='weighted')\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_clf, y_pred)\n",
    "print(f\"Test F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")"
   ],
   "id": "cc407fbdcf9b34c2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "print(classification_report(y_test_clf, y_pred))",
   "id": "a894389d477df328",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "\n",
    "precision, recall, thresholds = precision_recall_curve(y_test_clf, probs[:, 1])\n",
    "f1 = 2 * precision * recall / (precision + recall + 1e-8)\n",
    "best_t = thresholds[f1.argmax()]\n",
    "\n",
    "best_t\n"
   ],
   "id": "870989eb207c2121",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.heatmap(confusion_matrix(y_test_clf, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ],
   "id": "b7fbf001691b368",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "plt.plot(hist, label='Train Loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.title('Training Loss over Epochs')\n",
    "plt.legend()\n",
    "plt.show()"
   ],
   "id": "9a0dfda73deac918",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "fa8c808d9ab8a93b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Random Forest Classifier",
   "id": "9057c5d20b042751"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42, class_weight=\"balanced\")\n",
    "rf.fit(X_train_clf, y_train_clf)"
   ],
   "id": "1d67848aecee78ef",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "y_pred = rf.predict(X_train_clf)\n",
    "f1 = f1_score(y_train_clf, y_pred, average='weighted')\n",
    "accuracy = accuracy_score(y_train_clf, y_pred)\n",
    "print(f\"Train F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "y_pred = rf.predict(X_test_clf)\n",
    "f1 = sklearn.metrics.f1_score(y_test_clf, y_pred, average='weighted')\n",
    "accuracy = sklearn.metrics.accuracy_score(y_test_clf, y_pred)\n",
    "print(f\"Test F1: {f1:.4f}, Accuracy: {accuracy:.4f}\")\n",
    "print(classification_report(y_test_clf, y_pred))"
   ],
   "id": "e95040951e919270",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "sns.heatmap(confusion_matrix(y_test_clf, y_pred), annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Matrice de confusion\")\n",
    "plt.show()"
   ],
   "id": "6c6978ef7e9a545d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "b99725ec9fb88409",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

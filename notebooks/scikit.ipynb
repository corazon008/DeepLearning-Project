{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "74f2ba81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data_set_path = '../data/health_lifestyle_dataset_cleaned.csv'\n",
    "df = pd.read_csv('../data/health_lifestyle_dataset.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbeeb40a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 16 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   id                 100000 non-null  int64  \n",
      " 1   age                100000 non-null  int64  \n",
      " 2   gender             100000 non-null  object \n",
      " 3   bmi                100000 non-null  float64\n",
      " 4   daily_steps        100000 non-null  int64  \n",
      " 5   sleep_hours        100000 non-null  float64\n",
      " 6   water_intake_l     100000 non-null  float64\n",
      " 7   calories_consumed  100000 non-null  int64  \n",
      " 8   smoker             100000 non-null  int64  \n",
      " 9   alcohol            100000 non-null  int64  \n",
      " 10  resting_hr         100000 non-null  int64  \n",
      " 11  systolic_bp        100000 non-null  int64  \n",
      " 12  diastolic_bp       100000 non-null  int64  \n",
      " 13  cholesterol        100000 non-null  int64  \n",
      " 14  family_history     100000 non-null  int64  \n",
      " 15  disease_risk       100000 non-null  int64  \n",
      "dtypes: float64(3), int64(12), object(1)\n",
      "memory usage: 12.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f060a001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "0",
         "rawType": "int64",
         "type": "integer"
        }
       ],
       "ref": "600d8d87-82be-49a6-950a-da3c5520aa9e",
       "rows": [
        [
         "id",
         "0"
        ],
        [
         "age",
         "0"
        ],
        [
         "gender",
         "0"
        ],
        [
         "bmi",
         "0"
        ],
        [
         "daily_steps",
         "0"
        ],
        [
         "sleep_hours",
         "0"
        ],
        [
         "water_intake_l",
         "0"
        ],
        [
         "calories_consumed",
         "0"
        ],
        [
         "smoker",
         "0"
        ],
        [
         "alcohol",
         "0"
        ],
        [
         "resting_hr",
         "0"
        ],
        [
         "systolic_bp",
         "0"
        ],
        [
         "diastolic_bp",
         "0"
        ],
        [
         "cholesterol",
         "0"
        ],
        [
         "family_history",
         "0"
        ],
        [
         "disease_risk",
         "0"
        ]
       ],
       "shape": {
        "columns": 1,
        "rows": 16
       }
      },
      "text/plain": [
       "id                   0\n",
       "age                  0\n",
       "gender               0\n",
       "bmi                  0\n",
       "daily_steps          0\n",
       "sleep_hours          0\n",
       "water_intake_l       0\n",
       "calories_consumed    0\n",
       "smoker               0\n",
       "alcohol              0\n",
       "resting_hr           0\n",
       "systolic_bp          0\n",
       "diastolic_bp         0\n",
       "cholesterol          0\n",
       "family_history       0\n",
       "disease_risk         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n",
    "df.describe()\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "98822b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0ad94bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def preprocess_data(df, target):\n",
    "\n",
    "    if target not in df.columns:\n",
    "        raise ValueError(f\"Target column '{target}' not found in dataset.\")\n",
    "\n",
    "    X = df.drop(columns=[target])\n",
    "    y = df[target]\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24c7db",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess(X: pd.DataFrame, y: pd.Series):\n",
    "    \"\"\"\n",
    "    Split the dataset into training/testing sets (80/20) and standardize features.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X_train_scaled, X_test_scaled, y_train, y_test, scaler\n",
    "    \"\"\"\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X,\n",
    "        y,\n",
    "        test_size=0.2,\n",
    "        stratify=y,           # important for classification balance\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "    return X_train_scaled, X_test_scaled, y_train, y_test, scaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e7baed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_mlp(\n",
    "    X_train: np.ndarray,\n",
    "    y_train: np.ndarray,\n",
    "    hidden_layer_sizes=(64, 32),\n",
    "    learning_rate_init=1e-3,\n",
    "    batch_size=128,\n",
    "    max_iter=80\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a Multilayer Perceptron using Scikit-learn.\n",
    "\n",
    "    Justifications (for defense):\n",
    "    - Hidden layers : (64, 32) → ≤ 100 neurons each.\n",
    "    - ReLU activation → avoids vanishing gradients.\n",
    "    - Adam solver → robust for medium/large tabular datasets.\n",
    "    - Adaptive learning rate → improves convergence.\n",
    "    - Early stopping → avoids overfitting.\n",
    "    \"\"\"\n",
    "\n",
    "    model = MLPClassifier(\n",
    "        hidden_layer_sizes=hidden_layer_sizes,\n",
    "        activation=\"relu\",\n",
    "        solver=\"adam\",\n",
    "        batch_size=batch_size,\n",
    "        learning_rate_init=learning_rate_init,\n",
    "        learning_rate=\"adaptive\",\n",
    "        early_stopping=True,\n",
    "        max_iter=max_iter,\n",
    "        random_state=42,\n",
    "        verbose=True\n",
    "    )\n",
    "\n",
    "    start = time.time()\n",
    "    model.fit(X_train, y_train)\n",
    "    duration = time.time() - start\n",
    "\n",
    "    print(f\"\\n Training time: {duration:.2f} seconds\")\n",
    "\n",
    "    return model, duration\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "4683fb4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "\n",
    "  \n",
    "\n",
    "    y_pred_train = model.predict(X_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    print(\"\\n========== TRAIN METRICS ==========\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_train, y_pred_train))\n",
    "\n",
    "    print(\"\\n========== TEST METRICS ==========\")\n",
    "    print(\"Accuracy:\", accuracy_score(y_test, y_pred_test))\n",
    "\n",
    "    print(\"\\nClassification Report:\\n\")\n",
    "    print(classification_report(y_test, y_pred_test))\n",
    "\n",
    "    print(\"\\nConfusion Matrix:\\n\")\n",
    "    print(confusion_matrix(y_test, y_pred_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "df823770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    dataset_path = \"health_lifestyle_dataset_cleaned.csv\"\n",
    "    target_column = \"Diseases_risk\"\n",
    "\n",
    "    # (1) Load dataset\n",
    "    X, y = load_dataset(dataset_path, target_column)\n",
    "\n",
    "    print(f\"Dataset loaded: {X.shape[0]} samples, {X.shape[1]} features.\")\n",
    "\n",
    "    # (2) Preprocess\n",
    "    X_train, X_test, y_train, y_test, scaler = preprocess(X, y)\n",
    "\n",
    "    # (3) Train Scikit-learn MLP\n",
    "    model, train_time = train_mlp(\n",
    "        X_train,\n",
    "        y_train,\n",
    "        hidden_layer_sizes=(64, 32),\n",
    "        learning_rate_init=1e-3,\n",
    "        batch_size=256,\n",
    "        max_iter=100\n",
    "    )\n",
    "\n",
    "    # (4) Evaluate\n",
    "    evaluate(model, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
